# -*- coding: utf-8 -*-
"""ICA - Homework02.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1gTgwJdptLQas8XsgrBQSNrRUOhha1uyO

## Inicializando
"""

# Commented out IPython magic to ensure Python compatibility.
# Importando bibliotecas necessárias.
import pandas as pd
import numpy as np
import seaborn as sns #visualisation
import matplotlib.pyplot as plt #visualisation
# %matplotlib inline 
sns.set(color_codes=True)

from scipy.stats import norm
import matplotlib.pyplot as plt

from google.colab import drive
drive.mount('/content/drive')

tabela = pd.read_csv('/content/drive/MyDrive/Classroom/ICA20.2/abalone.csv',sep=';',decimal=',')
tabela = tabela.drop(columns=['Unnamed: 0'])

"""# Questão 00

"""

# Para exibir as 5 linhas principais (sem parâmetro = 5 linhas)
tabela.head(6)

# Para exibir as 6 linhas inferiores (sem parâmetro = 5 linhas)
tabela.tail(6)

# Verificando o tipo de dados
tabela.dtypes

# Número total de linhas e colunas
tabela.shape

# Usado para contar o número de linhas antes de remover os dados
tabela.count ()

# Encontrar os valores nulos. 
print (tabela.isnull (). sum ())

"""Como nâo foram identificados valores ausentes, não existe a necessidade de removê-los. 

"""

#Visão geral dos dados
tabela.describe()

"""Abaixo iremos identificar os valores discrepantes (outliers) do dataframe:"""

#Identificar valores discrepantes
sns.boxplot(x=tabela['LongestShell'])

#IQR Score Technique - Identificar e remover valores discrepantes
sns.boxplot(x=tabela['Diameter'])

#IQR Score Technique - Identificar e remover valores discrepantes
sns.boxplot(x=tabela['Height'])

#IQR Score Technique - Identificar e remover valores discrepantes
sns.boxplot(x=tabela['WholeWeight'])

#IQR Score Technique - Identificar e remover valores discrepantes
sns.boxplot(x=tabela['ShuckedWeight'])

#IQR Score Technique - Identificar e remover valores discrepantes
sns.boxplot(x=tabela['VisceraWeight'])

#IQR Score Technique - Identificar e remover valores discrepantes
sns.boxplot(x=tabela['ShellWeight'])

#IQR Score Technique - Identificar e remover valores discrepantes
sns.boxplot(x=tabela['Rings'])

"""Após identificados os outliers iremos removê-los, de forma que o dataframe final tenha valores que possam ser usados para a criação de um modelo mais preciso de regressão linear:"""

#Primeiramente iremos remover os outliers da coluna "LongestShell"
#z_scores = scipy.stats.zscore(tabela)

Q1 = tabela['LongestShell'].quantile(0.25)
Q3 = tabela['LongestShell'].quantile(0.75)
IQR = Q3 - Q1    #IQR is interquartile range. 

filter = (tabela['LongestShell'] >= Q1 - 1.5 * IQR) & (tabela['LongestShell'] <= Q3 + 1.5 *IQR)
#O novo dataframe será armazenado em tabela1
tabela1 = tabela.loc[filter]
tabela1

#Abaixo o dataframe sem outliers na coluna "LongestShell"
sns.boxplot(x=tabela1['LongestShell'])

# Removendo os outliers da coluna "Diameter"

Q1 = tabela1['Diameter'].quantile(0.25)
Q3 = tabela1['Diameter'].quantile(0.75)
IQR = Q3 - Q1    #IQR is interquartile range. 

filter = (tabela1['Diameter'] >= Q1 - 1.5 * IQR) & (tabela1['Diameter'] <= Q3 + 1.5 *IQR)
#O novo dataframe será armazenado em tabela2
tabela2 = tabela1.loc[filter]
tabela2

#Abaixo o dataframe sem outliers na coluna "Diameter"
sns.boxplot(x=tabela2['Diameter'])

# Removendo os outliers da coluna "Height"

Q1 = tabela2['Height'].quantile(0.25)
Q3 = tabela2['Height'].quantile(0.75)
IQR = Q3 - Q1    #IQR is interquartile range. 

filter = (tabela2['Height'] >= Q1 - 1.5 * IQR) & (tabela2['Height'] <= Q3 + 1.5 *IQR)
#O novo dataframe será armazenado em tabela3
tabela3 = tabela2.loc[filter]
tabela3

#Abaixo o dataframe sem outliers na coluna "Height"
sns.boxplot(x=tabela3['Height'])

# Removendo os outliers da coluna "WholeWeight"

Q1 = tabela3['WholeWeight'].quantile(0.25)
Q3 = tabela3['WholeWeight'].quantile(0.75)
IQR = Q3 - Q1    #IQR is interquartile range. 

filter = (tabela3['WholeWeight'] >= Q1 - 1.5 * IQR) & (tabela3['WholeWeight'] <= Q3 + 1.5 *IQR)
#O novo dataframe será armazenado em tabela4
tabela4 = tabela3.loc[filter]
tabela4

#Abaixo o dataframe sem outliers na coluna "WholeWeight"
sns.boxplot(x=tabela4['WholeWeight'])

# Removendo os outliers da coluna "ShuckedWeight"

Q1 = tabela4['ShuckedWeight'].quantile(0.25)
Q3 = tabela4['ShuckedWeight'].quantile(0.75)
IQR = Q3 - Q1    #IQR is interquartile range. 

filter = (tabela4['ShuckedWeight'] >= Q1 - 1.5 * IQR) & (tabela3['ShuckedWeight'] <= Q3 + 1.5 *IQR)
#O novo dataframe será armazenado em tabela5
tabela5 = tabela4.loc[filter]
tabela5

#Abaixo o dataframe sem outliers na coluna "ShuckedWeight"
sns.boxplot(x=tabela5['ShuckedWeight'])

# Removendo os outliers da coluna "VisceraWeight"

Q1 = tabela5['VisceraWeight'].quantile(0.25)
Q3 = tabela5['VisceraWeight'].quantile(0.75)
IQR = Q3 - Q1    #IQR is interquartile range. 

filter = (tabela5['VisceraWeight'] >= Q1 - 1.5 * IQR) & (tabela5['VisceraWeight'] <= Q3 + 1.5 *IQR)
#O novo dataframe será armazenado em tabela6
tabela6 = tabela5.loc[filter]
tabela6

#Abaixo o dataframe sem outliers na coluna "VisceraWeight"
sns.boxplot(x=tabela6['VisceraWeight'])

# Removendo os outliers da coluna "ShellWeight"

Q1 = tabela6['ShellWeight'].quantile(0.25)
Q3 = tabela6['ShellWeight'].quantile(0.75)
IQR = Q3 - Q1    #IQR is interquartile range. 

filter = (tabela6['ShellWeight'] >= Q1 - 1.5 * IQR) & (tabela6['ShellWeight'] <= Q3 + 1.5 *IQR)
#O novo dataframe será armazenado em tabela7
tabela7 = tabela6.loc[filter]
tabela7

#Abaixo o dataframe sem outliers na coluna "ShellWeight"
sns.boxplot(x=tabela7['ShellWeight'])

# Removendo os outliers da coluna "Rings"

Q1 = tabela7['Rings'].quantile(0.25)
Q3 = tabela7['Rings'].quantile(0.75)
IQR = Q3 - Q1    #IQR is interquartile range. 

filter = (tabela7['Rings'] >= Q1 - 1.5 * IQR) & (tabela7['Rings'] <= Q3 + 1.5 *IQR)
#O novo dataframe será armazenado em tabela8
tabela8 = tabela7.loc[filter]
tabela8

#Abaixo o dataframe sem outliers na coluna "Rings"
sns.boxplot(x=tabela8['Rings'])

# Encontrar as relações entre as variáveis.
plt.figure(figsize=(20,10))
c= tabela.corr()
sns.heatmap(c,annot=True)
c

# Traçando um gráfico de dispersão
fig, ax = plt.subplots (figsize = (10,6)) 
ax.scatter (tabela['Rings'], tabela['Diameter']) 
ax.set_xlabel ('Rings') 
ax.set_ylabel ('Diameter') 
plt.show ()

"""#Questão 01

Testamos datasets tratados de diferentes formas:
1. Dataset com outliers e tipos M, F e I (4177 linhas de dados)
* MSE = 4.90
* RMSE = 2.142
* R^2 = 0.53

2. Dataset sem outliers e tipos M, F e I (3773 linhas de dados)
* MSE = 2.73
* RMSE = 1.653
* R^2 = 0.49

3. Dataset sem outliers e tipos M e F (2512 linhas de dados)
* MSE = 3.00
* RMSE = 1.73
* R^2 = 0.29

Devido aos resultados apresentandos, resolvemos usar o modelo 2 (Dataset sem outliers e tipos M, F e I), como apresentado abaixo:
"""

data = pd.DataFrame({'type': ['M', 'F', 'I']})
data

#Como os valores de 'Type' (M, F e I) não podem ser utilizados na regressão linear, por serem string, fazemos a substituição dessas strings
#por valores númericos

tabela8['Type'].replace({'M':0, 'F':1, 'I':2}, inplace=True)

tabela8.head(20)

# Definimos as entradas eliminando a coluna "Rings" (axis=1: define que Rings é uma coluna)
X = tabela8.drop('Rings', axis=1)
X

#Rings será nossa saída/outcome
Y = tabela8.Rings
Y

from sklearn.model_selection import train_test_split
#Fazemos a divisão do dataset entre treino e teste, sendo 80% do dataset para o treino e 20% para o teste.
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=10)

from sklearn import linear_model
from sklearn.metrics import mean_squared_error, r2_score

X_train.head()

#Criamos inicialmente um modelo de regressão linear:
model = linear_model.LinearRegression()
#E então treinamos o modelo usando os dados de treino:
model.fit(X_train, Y_train)

#Aqui fazemos predições usando os dados de treino:
Y_pred_train = model.predict(X_train)

# Commented out IPython magic to ensure Python compatibility.
#Abaixo mostramos os valores de RMSE e de R² resultados do uso dos dados de treino:
import math
print('Coefficients:', model.coef_)
print('Intercept:', model.intercept_)
print('Mean squared error (MSE): %.2f'
#       % mean_squared_error(Y_train, Y_pred_train))
print('Root Mean squared error (RMSE): %.3f'
#       % math.sqrt(mean_squared_error(Y_train, Y_pred_train)))
print('Coefficient of determination (R^2): %.2f'
#       % r2_score(Y_train, Y_pred_train))

#Aqui fazemos predições usando os dados de teste:

Y_pred_test = model.predict(X_test)

# Commented out IPython magic to ensure Python compatibility.
#Abaixo mostramos os valores de RMSE e de R² resultados do uso dos dados de teste:
import math
print('Coefficients:', model.coef_)
print('Intercept:', model.intercept_)
print('Mean squared error (MSE): %.2f'
#       % mean_squared_error(Y_test, Y_pred_test))
print('Root Mean squared error (RMSE): %.3f'
#       % math.sqrt(mean_squared_error(Y_test, Y_pred_test)))
print('Coefficient of determination (R^2): %.2f'
#       % r2_score(Y_test, Y_pred_test))

"""Podemos comentar que para um bom modelo de regressão linear devemos ter valores de RMSE o mais próximo de 0 possível e valores de R² o mais próximo de 1 possível.
<br>

Quanto mais próximo de 1 o valor de R² melhor o modelo de regressão linear.
R² varia de 0 a 1 e se temos um valor de R² de 0,5 concluímos que o modelo de regressão linear pode prever 50% do que está no mundo real.
Quanto ao RMSE, quanto mais próximo de 0 o valor do RMSE, melhor o modelo de regressão linear. RMSE é uma medida do erro médio do resultado do modelo de regressão linear em relação ao mundo real. Por exemplo, se o RMSE é 1,6 concluímos que o modelo está errando em 1,6 anéis a mais ou a menos do valor do mundo real.
<br>

Nosso modelo de regressão linear apresentou os valores de:
<br>

Para os dados de treino: 
* RMSE: 1,653
* R²: 0,49 (49%)

<br>

Para os dados de teste:

* RMSE: 1,592
* R²: 0,54 (54%)

<br>

Os valores obtidos para os dados de treino e os dados de teste são bem próximos, com os valores obtidos com os dados de teste sendo um pouco melhores.

"""

#Agora iremos testar nosso dataset usando o método cross validation:

#Abaixo padronizamos os dados para fazer o cross validation:

from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()

#Padronizamos o set de treino e o set de teste
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform (X_test)

#Iremos usar 10 kfolds e ver os valores de RMSE e R² para cada um deles:
from sklearn.model_selection import KFold
from sklearn.metrics import mean_squared_error
from sklearn.metrics import r2_score
from sklearn.linear_model import LinearRegression
kf = KFold(n_splits=10)
resultadosr2 = []
resultadosrmse = []
cont = 1
for train_index, test_index in kf.split(X_train):
  X_train_cross, X_test_cross = X_train[train_index], X_train[test_index]
  y_train_cross, y_test_cross = Y_train.iloc[train_index], Y_train.iloc[test_index]
 
  model = LinearRegression()
  model.fit(X_train_cross, y_train_cross)

  y_pred = model.predict(X_test_cross)
  r2 = r2_score(y_test_cross, y_pred)
  resultadosr2.append(r2)
  print('KFold {}'.format(cont))
  print("Valor do R2: {}".format(r2))
  RMSE = mean_squared_error(y_test_cross, y_pred,squared=False)
  resultadosrmse.a   ppend(RMSE)
  print("Valor do RMSE: {}\n".format(RMSE))
  cont+=1

"""Como podemos ver acima, os valores de RMSE e R² continuaram próximos aos encontrados anteriormente. Iremos então fazer a média deles e obter também um valor próximo do obtido anteriormente:

"""

mediaR2 = np.mean(resultadosr2)
mediaRMSE = np.mean(resultadosrmse)
print("Média do R2: {}\nMédia do RMSE: {}".format(mediaR2, mediaRMSE))

#Abaixo vemos qual o resultado com o uso dos dados de teste para essa versão do modelo de regressão linear:
model.fit(X_train, Y_train)
y_pred = model.predict(X_test)
r2 = r2_score(Y_test, y_pred)
RMSE = mean_squared_error(Y_test, y_pred,squared=False)
print('R2: {}\nRMSE: {}\n'.format(r2, RMSE))

"""A seguir, iremos plotar alguns gráficos para demonstrar a relação entre o número de anéis preditos pelo nosso modelo e o valor real do número de anéis."""

def scatter_y(true_y, predicted_y):
    """Scatter-plot the prediro vs real número de anéis
    
    Plots:
       * predito vs real número de anéis
       * perfect agreement line
       * +2/-2 number dotted lines

    Returns the root mean square of the error
    """
    fig, ax = plt.subplots(figsize=(8, 8))
    ax.plot(true_y, predicted_y, '.k')
    
    ax.plot([0, 30], [0, 30], '--k')
    ax.plot([0, 30], [2, 32], ':k')
    ax.plot([2, 32], [0, 30], ':k')
    
    rms = (true_y - predicted_y).std()
    
    ax.text(25, 3,
            "Root Mean Square Error = %.2g" % rms,
            ha='right', va='bottom')

    ax.set_xlim(0, 30)
    ax.set_ylim(0, 30)
    
    ax.set_xlabel('Valor real do número de anéis')
    ax.set_ylabel('Número de anéis predito')
    
    return rms
    #Fonte: https://operational-machine-learning-pipeline.workshop.aws/assets/Model_Framing_Example.html

"""Plotando gráficos para melhor visualização do RMSE com os dados de treino e de teste"""

#Com os dados de treino:
predito_treino_y = model.predict(X_train)
scatter_y(Y_train, predito_treino_y)
plt.title("Plot com os dados de treino:")

predito_teste_y = model.predict(X_test)
scatter_y(Y_test, predito_teste_y)
plt.title("Plot com os dados de teste:")

"""# Questão 02

Iremos agora fazer uma regressão linear com base no modelo L2 (Ridge), e definimos o modelo a seguir:
"""

from sklearn.linear_model import Ridge
from sklearn.model_selection import cross_val_score

diferenca = 0.1
valR2 = [] #valores de R²
valRMSE = [] #valores de rmse
lamb = [] #valores de lambda
alpha = diferenca

for i in range(1, 11): #são usados 10 folds
  Rid = Ridge(alpha = alpha) #modelo usado é o Ridge com variações de alpha
  lamb.append(alpha)
  RMSE = np.mean((-1*cross_val_score(Rid, X_train, Y_train, cv=10, scoring='neg_mean_squared_error'))**0.5)
  R2 = np.mean(cross_val_score(Rid, X_train, Y_train, cv=10, scoring='r2'))
  valR2.append(R2)
  valRMSE.append(RMSE)
  
  print('lambda:', alpha)
  print('Média de R²: ', R2)
  print('Média de RMSE: ', RMSE)
  alpha= alpha + diferenca
  print()

plt.plot(lamb, valR2)
plt.xlabel('λ')
plt.ylabel('R²')

plt.plot(lamb, valRMSE)
plt.xlabel('λ')
plt.ylabel('RMSE')

"""Ele pega o melhor alfa (λ) da grade de valores entre 0 e 1 com uma separação de 0,1.Como observado pelos plots, o valor ótimo de λ será, no caso, 1, pois é o valor em que o RMSE é menor e o R² é maior.

A seguir usa-se os dados de teste no modelo:
"""

Rid.fit(X_train, Y_train)
y_predito = Rid.predict(X_test)
R2 = r2_score(Y_test, y_predito)
RMSE = mean_squared_error(Y_test, y_pred,squared=False)
print('R2:', R2)
print('RMSE:', RMSE)

"""Os valores obtidos com os  valores de teste são próximos aos valores obtidos com os valores de treino, mas ainda são melhores, pois o valor de R² é maior e o de RMSE é menor.

# Questão 03
"""

from sklearn.preprocessing import scale 
from sklearn import model_selection
from sklearn.model_selection import RepeatedKFold
from sklearn.model_selection import train_test_split
from sklearn.decomposition import PCA
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error

#Definindos o preditor e as variáveis de resposta
X = tabela8[["Type", "LongestShell", "Diameter", "Height", "WholeWeight", "ShuckedWeight", "VisceraWeight", "ShellWeight"]]
y = tabela8[["Rings"]]

pca = PCA()
X_reduced = pca.fit_transform(scale(X))

#Método de cross validation
cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)
regr = LinearRegression()
mse=[]
rmseli = []
r2lis=[]

#Calculando o MSE somente com o interceptor
score = -1*model_selection.cross_val_score(regr,
           np.ones((len(X_reduced),1)), y, cv=cv,
           scoring='neg_mean_squared_error').mean()    
mse.append(score)

# Calculando o MSE usando cross-validation, adicionando um componente por vez
for i in np.arange(1, 9):
    score = -1*model_selection.cross_val_score(regr,
               X_reduced[:,:i], y, cv=cv, scoring='neg_mean_squared_error').mean()
    score2 = model_selection.cross_val_score(regr,
               X_reduced[:,:i], y, cv=cv, scoring='r2').mean()
    rmse = score**0.5
    rmseli.append(rmse)
    r2lis.append(score2)
    print('Número de componentes:', i)
    print('R²:', score2)
    print('RMSE:', rmse)
    print()

# Plotando os resultados do cross-validation 
print('Plot dos resultados:')  
plt.plot(rmseli)
plt.xlabel('Número de componentes principais')
plt.ylabel('RMSE')
plt.title('RMSE X Número de componentes')

# Plotando os resultados do cross-validation 
print('Plot dos resultados:')  
plt.plot(r2lis)
plt.xlabel('Número de componentes principais')
plt.ylabel('R²')
plt.title('R² X Número de componentes')

"""Vemos que o RMSE decresce e o R² cresce à medida que se aumenta o número de componentes, por isso, concluímos que o número ótimo é o de 8 componentes, ou seja, usando todos os componentes.

Agora iremos testar nosso modelo:
"""

#dividindo os dados em dados de treino (70%) e dados de teste (30%)
X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3,random_state=0)

#Padronizando os dados
X_reduced_train = pca.fit_transform(scale(X_train))
X_reduced_test = pca.transform(scale(X_test))[:,:8]

#Treinando o modelo PCR model com os dados de treino
regr = LinearRegression()
regr.fit(X_reduced_train[:,:8], y_train)

#Calculando o RMSE e o R² com os dados de teste
pred = regr.predict(X_reduced_test)
rmse = np.sqrt(mean_squared_error(y_test, pred))
r2 = r2_score(y_test, pred)
print('RMSE:', rmse)
print('R²:', r2)